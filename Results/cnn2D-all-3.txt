Dream Networks are ready!
Label distribution in the train set  [[0.00000e+00 1.05891e+05]
 [1.00000e+00 1.22044e+05]
 [2.00000e+00 1.58065e+05]]
Label distribution in the validation set  [[0.000e+00 4.046e+03]
 [1.000e+00 5.973e+03]
 [2.000e+00 3.981e+03]]
Label distribution in the test set  [[0.0000e+00 5.9490e+03]
 [1.0000e+00 2.6061e+04]
 [2.0000e+00 2.7990e+04]]
Train matrix:  (386000, 32, 32, 1) (386000, 3)
Validation matrix:  (14000, 32, 32, 1) (14000, 3)
Test matrix:  (60000, 32, 32, 1) (60000, 3)
Building model and compiling functions...
PARAMETERS OF MODELS:  relu   5   256   0.5
Starting training...: model  Image-Single  batch size  100  with input  32_32_last20sec_img.npz
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        832       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632     
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 28, 28, 32)        25632     
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 14, 14, 64)        51264     
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 14, 14, 64)        102464    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 7, 7, 128)         204928    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         
_________________________________________________________________
flatten (Flatten)            (None, 1152)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               295168    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 771       
=================================================================
Total params: 732,323
Trainable params: 732,323
Non-trainable params: 0
_________________________________________________________________
Train on 386000 samples, validate on 14000 samples
Epoch 1/30
 - 54s - loss: 1.1122 - acc: 0.4082 - precision: 0.3332 - recall: 0.9997 - val_loss: 1.1412 - val_acc: 0.2806 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 2/30
 - 56s - loss: 1.1072 - acc: 0.4113 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.1342 - val_acc: 0.3031 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 3/30
 - 54s - loss: 1.0977 - acc: 0.4216 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.1163 - val_acc: 0.3784 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 4/30
 - 54s - loss: 1.0775 - acc: 0.4459 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.1122 - val_acc: 0.3931 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 5/30
 - 53s - loss: 1.0346 - acc: 0.4932 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.0604 - val_acc: 0.5014 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 6/30
 - 54s - loss: 0.9469 - acc: 0.5595 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.0221 - val_acc: 0.4950 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 7/30
 - 53s - loss: 0.8377 - acc: 0.6279 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.0876 - val_acc: 0.4962 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 8/30
 - 54s - loss: 0.7586 - acc: 0.6696 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.1626 - val_acc: 0.4962 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 9/30
 - 53s - loss: 0.7048 - acc: 0.6944 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.2141 - val_acc: 0.4749 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 10/30
 - 53s - loss: 0.6649 - acc: 0.7138 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.2334 - val_acc: 0.4930 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 11/30
 - 53s - loss: 0.6322 - acc: 0.7302 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.3099 - val_acc: 0.4851 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 12/30
 - 53s - loss: 0.6031 - acc: 0.7447 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.3755 - val_acc: 0.5020 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 13/30
 - 53s - loss: 0.5782 - acc: 0.7566 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.5138 - val_acc: 0.5094 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 14/30
 - 54s - loss: 0.5557 - acc: 0.7686 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.5435 - val_acc: 0.4943 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 15/30
 - 53s - loss: 0.5345 - acc: 0.7795 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.6720 - val_acc: 0.4956 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 16/30
 - 53s - loss: 0.5150 - acc: 0.7893 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.6543 - val_acc: 0.4788 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 17/30
 - 53s - loss: 0.4956 - acc: 0.7981 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.7113 - val_acc: 0.5088 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 18/30
 - 53s - loss: 0.4796 - acc: 0.8070 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.7895 - val_acc: 0.4744 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 19/30
 - 53s - loss: 0.4630 - acc: 0.8156 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.8718 - val_acc: 0.4770 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 20/30
 - 53s - loss: 0.4473 - acc: 0.8229 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.9505 - val_acc: 0.4984 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 21/30
 - 53s - loss: 0.4338 - acc: 0.8293 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.9937 - val_acc: 0.4898 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 22/30
 - 53s - loss: 0.4197 - acc: 0.8363 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.9963 - val_acc: 0.4927 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 23/30
 - 53s - loss: 0.4075 - acc: 0.8425 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.1453 - val_acc: 0.5007 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 24/30
 - 53s - loss: 0.3953 - acc: 0.8486 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.0283 - val_acc: 0.5033 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 25/30
 - 53s - loss: 0.3836 - acc: 0.8542 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.1212 - val_acc: 0.5009 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 26/30
 - 53s - loss: 0.3735 - acc: 0.8586 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.2170 - val_acc: 0.4806 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 27/30
 - 53s - loss: 0.3637 - acc: 0.8628 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.2557 - val_acc: 0.4985 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 28/30
 - 53s - loss: 0.3539 - acc: 0.8682 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.2681 - val_acc: 0.4979 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 29/30
 - 53s - loss: 0.3448 - acc: 0.8724 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.3584 - val_acc: 0.4849 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 30/30
 - 53s - loss: 0.3354 - acc: 0.8762 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.4750 - val_acc: 0.4889 - val_precision: 0.3333 - val_recall: 1.0000
[15848 18208 25944]
Accuracy: 43.27%
Label distribution in the train set  [[0.0000e+00 1.2561e+04]
 [1.0000e+00 1.4694e+04]
 [2.0000e+00 1.8486e+04]]
Label distribution in the validation set  [[  0. 237.]
 [  1. 711.]
 [  2. 711.]]
Label distribution in the test set  [[0.000e+00 9.480e+02]
 [1.000e+00 2.844e+03]
 [2.000e+00 3.555e+03]]
Train matrix:  (45741, 32, 32, 2) (45741, 3)
Validation matrix:  (1659, 32, 32, 2) (1659, 3)
Test matrix:  (7347, 32, 32, 2) (7347, 3)
Building model and compiling functions...
Starting training...: model  Image-Multi  batch size  10  with input  32_32_multichannel_img.npz
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 30, 30, 32)        608       
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 30, 30, 32)        9248      
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 15, 15, 64)        36928     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 7, 7, 128)         73856     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1152)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               295168    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 771       
=================================================================
Total params: 453,571
Trainable params: 453,571
Non-trainable params: 0
_________________________________________________________________
Train on 45741 samples, validate on 1659 samples
Epoch 1/30
 - 34s - loss: 1.1085 - acc: 0.4115 - precision: 0.3333 - recall: 0.9998 - val_loss: 1.0727 - val_acc: 0.4491 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 2/30
 - 33s - loss: 1.0856 - acc: 0.4406 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.0769 - val_acc: 0.4792 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 3/30
 - 33s - loss: 1.0095 - acc: 0.5211 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.1973 - val_acc: 0.3665 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 4/30
 - 33s - loss: 0.9074 - acc: 0.5971 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.3479 - val_acc: 0.3828 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 5/30
 - 33s - loss: 0.8024 - acc: 0.6583 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.6881 - val_acc: 0.4033 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 6/30
 - 33s - loss: 0.7181 - acc: 0.6993 - precision: 0.3333 - recall: 1.0000 - val_loss: 1.8577 - val_acc: 0.4231 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 7/30
 - 33s - loss: 0.6534 - acc: 0.7261 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.4345 - val_acc: 0.3900 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 8/30
 - 33s - loss: 0.6026 - acc: 0.7489 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.4154 - val_acc: 0.4057 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 9/30
 - 33s - loss: 0.5687 - acc: 0.7606 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.5683 - val_acc: 0.4153 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 10/30
 - 34s - loss: 0.5391 - acc: 0.7754 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.7626 - val_acc: 0.4406 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 11/30
 - 33s - loss: 0.5148 - acc: 0.7857 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.9131 - val_acc: 0.4304 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 12/30
 - 33s - loss: 0.4925 - acc: 0.7955 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.8058 - val_acc: 0.4298 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 13/30
 - 32s - loss: 0.4735 - acc: 0.8056 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.0839 - val_acc: 0.4310 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 14/30
 - 33s - loss: 0.4536 - acc: 0.8143 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.0747 - val_acc: 0.4382 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 15/30
 - 33s - loss: 0.4399 - acc: 0.8220 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.6785 - val_acc: 0.4231 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 16/30
 - 33s - loss: 0.4262 - acc: 0.8302 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.9248 - val_acc: 0.4358 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 17/30
 - 33s - loss: 0.4087 - acc: 0.8375 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.0362 - val_acc: 0.4412 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 18/30
 - 33s - loss: 0.3948 - acc: 0.8446 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.3144 - val_acc: 0.4171 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 19/30
 - 33s - loss: 0.3896 - acc: 0.8483 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.2135 - val_acc: 0.4262 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 20/30
 - 33s - loss: 0.3720 - acc: 0.8559 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.1776 - val_acc: 0.4201 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 21/30
 - 33s - loss: 0.3638 - acc: 0.8626 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.4060 - val_acc: 0.4436 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 22/30
 - 33s - loss: 0.3492 - acc: 0.8680 - precision: 0.3333 - recall: 1.0000 - val_loss: 2.9906 - val_acc: 0.4274 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 23/30
 - 33s - loss: 0.3356 - acc: 0.8758 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.3902 - val_acc: 0.4189 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 24/30
 - 33s - loss: 0.3316 - acc: 0.8755 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.4647 - val_acc: 0.3828 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 25/30
 - 34s - loss: 0.3191 - acc: 0.8809 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.9602 - val_acc: 0.3900 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 26/30
 - 33s - loss: 0.3084 - acc: 0.8868 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.7446 - val_acc: 0.4183 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 27/30
 - 33s - loss: 0.3042 - acc: 0.8903 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.4055 - val_acc: 0.4231 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 28/30
 - 33s - loss: 0.2948 - acc: 0.8939 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.5126 - val_acc: 0.4171 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 29/30
 - 33s - loss: 0.2838 - acc: 0.8998 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.1980 - val_acc: 0.4473 - val_precision: 0.3333 - val_recall: 1.0000
Epoch 30/30
 - 33s - loss: 0.2851 - acc: 0.8990 - precision: 0.3333 - recall: 1.0000 - val_loss: 3.7225 - val_acc: 0.4316 - val_precision: 0.3333 - val_recall: 1.0000
[1453 3066 2828]
Accuracy: 47.00%
All done!
