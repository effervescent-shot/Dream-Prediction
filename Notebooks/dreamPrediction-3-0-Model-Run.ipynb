{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DreamNetworks is ready!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from dreamUtils import *\n",
    "from dreamNetworks import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data-test/'\n",
    "channels_coord = DATA_DIR + 'channelcoords.mat'\n",
    "files = os.listdir(DATA_DIR)\n",
    "files.remove('channelcoords.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_labels = {'file': ['JL02trial_1.mat','JL02trial_2.mat','JL02trial_3.mat','JL02trial_4.mat',\n",
    "#                        'JL02trial_5.mat','JL02trial_6.mat','JL02trial_7.mat','JL02trial_8.mat',\n",
    "#                        'JL02trial_9.mat','JL02trial_10.mat','JL02trial_11.mat','JL02trial_12.mat', \n",
    "#                        'JL02trial_13.mat','JL02trial_14.mat','JL02trial_15.mat','JL02trial_16.mat',\n",
    "#                        'JL02trial_17.mat','JL02trial_18.mat','JL02trial_19.mat','JL02trial_20.mat',\n",
    "#                        'JL02trial_21.mat','JL02trial_22.mat','JL02trial_23.mat', 'JL02trial_24.mat'],\n",
    "#               'label': [2,2,2,2,2,2,2,1,2,2,0,2,2,2,1,2,1,2,2,2,2,2,2,2]}\n",
    "\n",
    "files_labels = {'file': ['JL02trial_8.mat','JL02trial_11.mat'],\n",
    "              'label': [1,0]}\n",
    "\n",
    "labels_df =  pd.DataFrame.from_dict(files_labels).set_index('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 3)\n",
      "(256, 2)\n"
     ]
    }
   ],
   "source": [
    "locs_3D = sio.loadmat(channels_coord)['locstemp']\n",
    "print(locs_3D.shape)\n",
    "locs_2D = map_to_2d(locs_3D)\n",
    "print(locs_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_data_labels = []\n",
    "\n",
    "for single_trial in labels_df.index:\n",
    "    label = labels_df.get_value(single_trial, 'label')\n",
    "    #take last 20 seconds and 256 electrodes\n",
    "    #referecence electrode is excluded\n",
    "    a_trial = ((sio.loadmat(DATA_DIR + single_trial)['a_trial']).T)[-10000:,0:256]\n",
    "    all_data.append(a_trial)\n",
    "    all_data_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_trial = sio.loadmat('/home/ezgi/Desktop/SemesterProject_EPFL/EEGLearn/Sample data/FeatureMat_timeWin.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2670, 1345)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_trial['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 file \"H009_E1_NREM_S01.mat\" (mode r)>)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/H009_E1_NREM_S01.mat','r') as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = {}\n",
    "f = h5py.File('./data/H009_E1_NREM_S01.mat')\n",
    "for k, v in f.items():\n",
    "    arrays[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394125, 257)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays['datavr'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_trial = sio.loadmat(DATA_DIR + 'JL02trial_3.mat')['a_trial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.90494   ,   5.456661  ,   3.7931693 , ..., -46.28712   ,\n",
       "        -48.23105   , -46.852055  ],\n",
       "       [  5.761282  ,   5.3931656 ,   4.0317554 , ..., -43.170185  ,\n",
       "        -44.438335  , -42.915382  ],\n",
       "       [  4.797691  ,   4.529368  ,   3.3924654 , ..., -35.585415  ,\n",
       "        -36.068577  , -34.327198  ],\n",
       "       ...,\n",
       "       [  0.70536757,   1.0350038 ,  -1.6873348 , ..., -38.038395  ,\n",
       "        -40.55295   , -38.59091   ],\n",
       "       [  1.4886457 ,   1.6795789 ,  -0.9567653 , ..., -38.62174   ,\n",
       "        -41.44178   , -39.558346  ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1\n",
       "0    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high bias !!!\n",
    "labels_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab(y, sample_size):\n",
    "    return [y]*sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each image the label of trial\n",
    "# here, 10000 image is taken from each trial is known\n",
    "labels= np.concatenate( [lab(y, 10000) for y in all_data_labels]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated 10000/10000"
     ]
    }
   ],
   "source": [
    "# create an image per time step\n",
    "data = np.concatenate([gen_images(locs_2D, X , 32, normalize=False,\n",
    "                augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False) for X in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels,test_size=0.2, random_state=1453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make labels categorical\n",
    "y_train_32 = np_utils.to_categorical(y_train)\n",
    "y_test_32 = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 1, 32, 32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Image32()  # TODO::Forget to compile\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([2012,  988]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test[:,2], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct input shape before feeding to CNN\n",
    "X_train_32 = X_train.reshape(-1,32,32,1)\n",
    "X_test_32 = X_test.reshape(-1,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/3\n",
      "12000/12000 [==============================] - 100s 8ms/step - loss: 10.2670 - acc: 0.3599 - val_loss: 10.4714 - val_acc: 0.3503\n",
      "Epoch 2/3\n",
      "12000/12000 [==============================] - 104s 9ms/step - loss: 10.3142 - acc: 0.3601 - val_loss: 10.4714 - val_acc: 0.3503\n",
      "Epoch 3/3\n",
      "12000/12000 [==============================] - 102s 9ms/step - loss: 10.3142 - acc: 0.3601 - val_loss: 10.4714 - val_acc: 0.3503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa90a87240>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train_32, y_train, validation_data=(X_test_32, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 0, 2, 2, 2, 1, 2, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create model\n",
    "model = Sequential()\n",
    "# add layers\n",
    "# activation is NONE  \n",
    "#model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(32,32,1), \n",
    "                 kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 55s 3ms/step - loss: 8.0859 - acc: 0.4976 - val_loss: 7.8858 - val_acc: 0.5108\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 57s 4ms/step - loss: 8.1024 - acc: 0.4973 - val_loss: 7.8858 - val_acc: 0.5108\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 59s 4ms/step - loss: 8.1024 - acc: 0.4973 - val_loss: 7.8858 - val_acc: 0.5108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffb28913588>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train_32, y_train_32, validation_data=(X_test_32, y_test_32), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
