{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezgi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dreamUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_3D = sio.loadmat('./data/channelcoords.mat')['locstemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(locs_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60003, 257)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_trial = (sio.loadmat('./data/JL02trial_1.mat')['a_trial']).T\n",
    "single_trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take last 20 seconds and 256 electrodes\n",
    "#referecence electrode is excluded\n",
    "single_trial = single_trial[-10000:,0:256]\n",
    "single_trial.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random labels for test purpose\n",
    "single_trial_labels = np.random.randint(3, size= single_trial.shape[0])\n",
    "single_trial_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(single_trial, single_trial_labels, \\\n",
    "                                                    test_size=0.2, random_state=1453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels as one-hot vectors\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated 100/100\r",
      "\r"
     ]
    }
   ],
   "source": [
    "locs_2D = map_to_2d(locs_3D)\n",
    "images = gen_images(locs_2D, X_train[:100,:] , 32, normalize=False,\n",
    "               augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO HIDDEN LAYER NN \n",
    "\n",
    "model = Sequential()\n",
    "# first layer\n",
    "model.add(Dense(128,   # or 100\n",
    "                input_dim=256, \n",
    "                kernel_initializer='normal',   # 'normal', initializers.Constant(value=0), ...\n",
    "#                 kernel_regularizer=regularizers.l2(0.01),  # smooth filters, but bad accuracy\n",
    "                activation='sigmoid'))  # 'relu', 'sigmoid', 'tanh', ...\n",
    "# second layer\n",
    "model.add(Dense(32, \n",
    "                kernel_initializer='normal',   # 'normal', ...\n",
    "#                 kernel_regularizer=regularizers.l2(0.1),  # smooth filters, but bad accuracy\n",
    "                activation='sigmoid'))\n",
    "# third layer\n",
    "model.add(Dense(8, \n",
    "                kernel_initializer='normal',   # 'normal', ...\n",
    "#                 kernel_regularizer=regularizers.l2(0.1),  # smooth filters, but bad accuracy\n",
    "                activation='sigmoid'))\n",
    "\n",
    "# last layer\n",
    "model.add(Dense(3, \n",
    "                kernel_initializer='normal',   # 'normal', ...\n",
    "#                 kernel_regularizer=regularizers.l2(0.1),  # smooth filters, but bad accuracy\n",
    "                activation='softmax'))\n",
    "\n",
    "\n",
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', # 'adam', optimizers.SGD(lr=0.1), ...\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10, verbose=2)\n",
    "# scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN  (for 16x16 EEG images)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_16 = X_train.reshape(-1,16,16,1)\n",
    "X_test_16 = X_test.reshape(-1,16,16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# add layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(16,16,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "#model.fit(X_train_16, y_train, validation_data=(X_test_16, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN (AEP for 32x32 images)\n",
    "### Architecture D (Bashivan2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated 2000/2000"
     ]
    }
   ],
   "source": [
    "# AEP map of electrodes from 3D to 2D space \n",
    "locs_2D = map_to_2d(locs_3D)\n",
    "# Generate single-channel train images\n",
    "train_images = gen_images(locs_2D, X_train , 32, normalize=False,\n",
    "                augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False)\n",
    "# Generate single-channel test images\n",
    "test_images = gen_images(locs_2D, X_test , 32, normalize=False,\n",
    "                augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1, 32, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1eb49fe550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(train_images[5].reshape(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how transpose function works\n",
    "#deneme = np.transpose(train_images, (0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct input shape before feeding to CNN\n",
    "X_train_32 = train_images.reshape(-1,32,32,1)\n",
    "X_test_32 = test_images.reshape(-1,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# add layers\n",
    "# activation is NONE  #model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(32,32,1), kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# after max-pooling\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# another max-pooling\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "#model.fit(X_train_32, y_train, validation_data=(X_test_32, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN (AEP for 32x32 images - Multichannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## format data in correct manner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# add layers\n",
    "# activation is NONE  #model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(32,32,1), kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# after max-pooling\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# another max-pooling\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', kernel_initializer='glorot_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "#model.fit(X_train_32, y_train, validation_data=(X_test_32, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN (for Tx32x32 EEG Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import theano\n",
    "import cv2 as cv\n",
    "from keras.layers import Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32, 32, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many frame a video will consist\n",
    "#####TODO: do not forget to divide labels\n",
    "def divide_into_timeslots(time_slot, data):\n",
    "    data_list = []\n",
    "    for t in range(int(data.shape[0]/time_slot)):\n",
    "        data_list.append(data[t * time_slot:(t + 1) * time_slot,:,:,:])\n",
    "\n",
    "    return np.asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v_100 = divide_into_timeslots(time_slot= 10, data= X_train_32)\n",
    "X_test_v_100 =  divide_into_timeslots(time_slot= 10, data= X_test_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 10, 32, 32, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_v_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# add layers\n",
    "model.add(Conv3D(32, kernel_size=3, input_shape=(10,32,32,1)))\n",
    "model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# new layer\n",
    "model.add(Conv3D(64, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(Conv3D(64, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# flatten and check\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "#model.fit(X_train_v_100,y_train[:800], validation_data=(X_test_v_100, y_test[:200]), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN (for Tx32x32 EEG Videos - Multichannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT FORGET TO CHANGE DATA FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# add layers\n",
    "model.add(Conv3D(32, kernel_size=3, input_shape=(10,32,32,2)))\n",
    "model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# new layer\n",
    "model.add(Conv3D(64, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(Conv3D(64, kernel_size=3, strides=(1,1,1), dilation_rate=(1,1,1), padding='same' ))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "# flatten and check\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "#model.fit(X_train_v_100,y_train[:800], validation_data=(X_test_v_100, y_test[:200]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet+LSTM (Bashivan2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet+LSTM/1D-Conv(Bashivan2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
